{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e91d9-d98a-4e07-b3d6-9241c2f13ad8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%pip install IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e408d751-5441-4487-939a-4c00356e0a34",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "from IPython.core.magic import register_cell_magic\n",
    "from IPython import get_ipython\n",
    "# Conditional skipping of https://kioku-space.com/en/jupyter-skip-execution/\n",
    "@register_cell_magic\n",
    "def skip_if(line, cell):\n",
    "    if eval(line):\n",
    "        return\n",
    "    get_ipython().run_cell(cell)\n",
    "\n",
    "get_ipython().register_magic_function(skip_if, 'cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d6f9e1-fe1a-45af-9000-e93ca342c2ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%skip_if importlib.util.find_spec('Jinja2') is not None\n",
    "%pip install Jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35e8aa-a7a8-423d-84aa-59659696235f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%skip_if importlib.util.find_spec('nbformat') is not None\n",
    "%pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271dc7df-e5c0-4930-b203-2b55ec971854",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%skip_if importlib.util.find_spec('pyproj') is not None\n",
    "%pip install pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefeba90-90c9-4b26-b55a-ff0890ef86ed",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import mercury as mr\n",
    "import nbformat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##PythonLibraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import plotly.graph_objects as go\n",
    "from pyproj import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92cf7f-69b7-4956-9c0d-0305c9d529a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = mr.App(\n",
    "    title=\"CS 365: Transit Regina Data Wrangling\", \n",
    "    description=\"Cleaning and transforming Transit Regina data for analysis\", \n",
    "    show_code=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d571cd7-81a1-4b1a-b589-acfdb6fc7e76",
   "metadata": {},
   "source": [
    " # CS 365 Final Project: Transit Regina Data Wrangling\n",
    "\n",
    " **Data Source:** City of Regina Open Data Portal\n",
    " **Dataset:** Transit Stops, Routes, and GTFS Schedule Data\n",
    " **Date:** December 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa7cc4-f39b-44f8-9f8c-b9e542af5ad4",
   "metadata": {},
   "source": [
    " ## Dataset Source & License\n",
    "\n",
    " **Source:** [City of Regina Open Data Portal](https://open.regina.ca)\n",
    "\n",
    " **Files:**\n",
    " - Bus Stop Locations (yqrStops20251120.json) - 1,000 stops\n",
    " - Transit Routes (yqrRoutes20251120.json) - 22 routes\n",
    " - GTFS Schedule Data (stops.txt, routes.txt, trips.txt, stop_times.txt)\n",
    "\n",
    " **License:** Open Government License - Regina\n",
    " ✅ Allows educational and commercial use\n",
    " ✅ No PII - only public infrastructure data\n",
    "\n",
    " **Why this matters:** Understanding transit accessibility and service patterns for urban planning and public transit analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2c465f-b9f3-4de9-97fa-1008c9182de4",
   "metadata": {},
   "source": [
    " ## Raw Data Snapshot: Bus Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5907e94-a90a-4d40-a85d-9c687105b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "```python\n",
    "# Load JSON data\n",
    "with open('raw_data/yqrStops20251120.json', 'r') as f:\n",
    "    stop_data = json.load(f)\n",
    "\n",
    "# Normalize nested JSON structure\n",
    "df_stops = pd.json_normalize(stop_data['features'])\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ea8223-1cf0-43cb-9d47-8ff665fdb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stop data\n",
    "try:\n",
    "    with open('raw_data/yqrStops.json', 'r') as f:\n",
    "        stop_data = json.load(f)\n",
    "except json.decoder.JSONDecodeError as e:\n",
    "    print(\"Invalid JSON\", e)\n",
    "\n",
    "df_stops = pd.json_normalize(stop_data['features'])\n",
    "\n",
    "mr.Markdown(f\"**Loaded {len(df_stops)} bus stops**\")\n",
    "df_stops[['attributes.STOP_ID','attributes.ONSTREET', 'attributes.ATSTREET', 'attributes.LAT', 'attributes.LON']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902cab13-d425-4968-9dba-31cb5b201582",
   "metadata": {},
   "source": [
    " ## Data Profiling: Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19736af5-7cfa-4c76-a5bd-76431c3eb4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "### Checking data quality issues:\n",
    "- **Data types** - Are coordinates stored correctly?\n",
    "- **Missing values** - Which columns have gaps?\n",
    "- **Duplicates** - Any duplicate stop IDs?\n",
    "- **Outliers** - Any stops in unexpected locations?\n",
    "- **Cardinalities** - How many unique values?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402b38a-173e-4ce0-9dda-2bbcecfb34ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== BUS STOP DATA TYPES ===\")\n",
    "print(df_stops.dtypes[df_stops.columns[:8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe28dd-9cee-433f-954e-e4534970c1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "missing = df_stops.isnull().sum()\n",
    "print(missing[missing > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9c9584-0250-453c-a81a-50255ec00b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== DUPLICATES ===\")\n",
    "duplicates = df_stops.duplicated(subset=['attributes.STOP_ID']).sum()\n",
    "print(f\"Duplicate stop IDs: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003a67e-50a2-4e62-8c7d-5818c3aab85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== SAMPLE RAW DATA (showing quality issues) ===\")\n",
    "print(\"Notice: Mixed case, whitespace, coordinates stored as strings\")\n",
    "df_stops[['attributes.STOP_ID','attributes.ONSTREET', 'attributes.ATSTREET', 'attributes.LAT']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a685baeb-ac8f-4067-9cfe-32089c2736b2",
   "metadata": {},
   "source": [
    " ## Cleaning Step 1: Text Standardization & Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963332d-758d-4ce2-89f9-0dfc13fe9fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "**Problems identified:**\n",
    "- Inconsistent text formatting (mixed case, whitespace)\n",
    "- Coordinates stored as strings instead of numeric\n",
    "- Missing values in street names\n",
    "\n",
    "**Solutions:**\n",
    "```python\n",
    "# Text standardization\n",
    "df_stops['attributes.ONSTREET'] = df_stops['attributes.ONSTREET'].str.strip().str.upper()\n",
    "df_stops['attributes.ATSTREET'] = df_stops['attributes.ATSTREET'].str.strip().str.upper()\n",
    "\n",
    "# Type conversion\n",
    "df_stops = df_stops.astype({'attributes.STOP_ID': 'int32'})\n",
    "\n",
    "# Missing value imputation\n",
    "df_stops = df_stops.fillna({'attributes.ATSTREET': \"DOROTHY ST (SB)\"})\n",
    "\n",
    "# Data correction\n",
    "df_stops['attributes.ONSTREET'] = df_stops['attributes.ONSTREET'].str.replace(\n",
    "    \"1060 DOROTHY ST (SB)\", \"DOROTHY ST\", regex=False\n",
    ")\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5492f146-d052-4fce-8fd9-e500b7b5795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning function\n",
    "def clean_data(df_stops):\n",
    "    df_stops['attributes.ONSTREET'] = df_stops['attributes.ONSTREET'].str.strip().str.upper()\n",
    "    df_stops['attributes.ATSTREET'] = df_stops['attributes.ATSTREET'].str.strip().str.upper()\n",
    "    df_stops['attributes.LON'] = df_stops['attributes.LON'].str.strip()\n",
    "    df_stops['attributes.LAT'] = df_stops['attributes.LAT'].str.strip()\n",
    "    df_stops['attributes.STOP_ID'] = df_stops['attributes.STOP_ID'].str.strip()\n",
    "    df_stops['attributes.STOP_NAME'] = df_stops['attributes.STOP_NAME'].str.strip().str.upper()\n",
    "    df_stops['attributes.GLOBALID'] = df_stops['attributes.GLOBALID'].str.strip()\n",
    "    df_stops = df_stops.fillna({'attributes.ATSTREET':\"DOROTHY ST (SB)\"})\n",
    "    df_stops['attributes.ONSTREET'] = df_stops['attributes.ONSTREET'].str.replace(\"1060 DOROTHY ST (SB)\", \"DOROTHY ST\", case=False, regex=False)\n",
    "    df_stops = df_stops.astype({'attributes.STOP_ID': 'int32'})\n",
    "    \n",
    "    # Rename for clarity\n",
    "    df_stops = df_stops.rename(columns={\n",
    "        'attributes.ONSTREET': 'on_street',\n",
    "        'attributes.ATSTREET': 'at_street',\n",
    "        'attributes.LON': 'lon',\n",
    "        'attributes.LAT': 'lat',\n",
    "        'attributes.STOP_ID': 'stop_id',\n",
    "        'attributes.STOP_NAME': 'stop_name',\n",
    "        'attributes.GLOBALID': 'global_id',\n",
    "        'attributes.OBJECTID': 'object_id'\n",
    "    })\n",
    "    return df_stops\n",
    "\n",
    "clean_stops = clean_data(df_stops.copy())\n",
    "\n",
    "mr.Markdown(f\"✅ **Cleaned {len(clean_stops)} bus stops**\")\n",
    "clean_stops[['stop_id', 'on_street', 'at_street', 'lat', 'lon']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad1c46-342b-4318-b4e9-42aa1f53f367",
   "metadata": {},
   "source": [
    " ## Loading & Cleaning Routes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb130b8-3713-4b14-9a8a-9f47f26cc8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "```python\n",
    "# Load routes data\n",
    "with open('raw_data/yqrRoutes.json', 'r') as f:\n",
    "    routes_data = json.load(f)\n",
    "\n",
    "df_routes = pd.json_normalize(routes_data['features'])\n",
    "\n",
    "# Clean and standardize\n",
    "df_routes['attributes.ROUTE_NAME'] = df_routes['attributes.ROUTE_NAME'].str.strip().str.upper()\n",
    "df_routes['attributes.ROUTE_COLOR'] = '#' + df_routes['attributes.ROUTE_COLOR'].str.strip()\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bbf69d-35fd-4448-bd3d-aec80e8c0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load routes\n",
    "try:\n",
    "    with open('raw_data/yqrRoutes.json', 'r') as f:\n",
    "        routes_data = json.load(f)\n",
    "except json.decoder.JSONDecodeError as e:\n",
    "    print(\"Invalid JSON\", e)\n",
    "\n",
    "df_routes = pd.json_normalize(routes_data['features'])\n",
    "\n",
    "# Clean routes\n",
    "def clean_data(df_routes):\n",
    "    df_routes['attributes.ROUTE_NAME'] = df_routes['attributes.ROUTE_NAME'].str.strip().str.upper()\n",
    "    df_routes['attributes.ROUTE_NUM'] = df_routes['attributes.ROUTE_NUM'].str.strip()\n",
    "    df_routes['attributes.ROUTE_ID'] = df_routes['attributes.ROUTE_ID'].str.strip()\n",
    "    df_routes['attributes.ROUTE_COLOR'] = '#' + (df_routes['attributes.ROUTE_COLOR'].str.strip()).astype(str)\n",
    "    df_routes = df_routes.fillna({'attributes.ROUTE_TEXT_COLOR': \"FFFFFF\"})\n",
    "    df_routes['attributes.ROUTE_TEXT_COLOR'] = \"#\"+ (df_routes['attributes.ROUTE_TEXT_COLOR'].str.strip()).astype(str)\n",
    "    \n",
    "    df_routes = df_routes.rename(columns={\n",
    "        'attributes.SHAPE.LEN': 'shape_length',\n",
    "        'attributes.ROUTE_NAME': 'route_name',\n",
    "        'attributes.ROUTE_NUM': 'route_num',\n",
    "        'attributes.ROUTE_ID': 'route_id',\n",
    "        'attributes.ROUTE_COLOR': 'route_color',\n",
    "        'attributes.ROUTE_TEXT_COLOR': 'route_text_color',\n",
    "        'geometry.paths': 'geometry_paths',\n",
    "        'attributes.OBJECTID': 'object_id'\n",
    "    })\n",
    "    return df_routes\n",
    "\n",
    "clean_routes = clean_data(df_routes.copy())\n",
    "\n",
    "mr.Markdown(f\"✅ **Cleaned {len(clean_routes)} routes**\")\n",
    "clean_routes[['route_num', 'route_name', 'route_color']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b0f6b5-7944-468a-aeb4-9b3ae5d12ea3",
   "metadata": {},
   "source": [
    " ## Profiling Routes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99528964-4163-450c-8ccd-6b25b7f0f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ROUTE DATA TYPES ===\")\n",
    "print(clean_routes.dtypes[clean_routes.columns[:6]])\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "missing = clean_routes.isnull().sum()\n",
    "print(missing[missing > 0] if len(missing[missing > 0]) > 0 else \"No missing values\")\n",
    "print(\"\\n=== DUPLICATES ===\")\n",
    "duplicates = clean_routes.duplicated(subset=['route_id']).sum()\n",
    "print(f\"Duplicate route IDs: {duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560d480d-d76b-4ca1-8654-039d88dc6156",
   "metadata": {},
   "source": [
    " ## Transformation 1: Loading GTFS Schedule Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5440f20b-144b-4805-bdd2-97b2e85edd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "**GTFS (General Transit Feed Specification)** provides detailed schedule information:\n",
    "\n",
    "```python\n",
    "# Load GTFS files\n",
    "stops_gtfs = pd.read_csv('raw_data/gtfs_data/stops.txt')\n",
    "routes_gtfs = pd.read_csv('raw_data/gtfs_data/routes.txt')\n",
    "trips_gtfs = pd.read_csv('raw_data/gtfs_data/trips.txt')\n",
    "times_gtfs = pd.read_csv('raw_data/gtfs_data/stop_times.txt')\n",
    "\n",
    "# Clean and standardize\n",
    "stops_gtfs['stop_name'] = stops_gtfs['stop_name'].str.upper().str.strip()\n",
    "routes_gtfs['route_long_name'] = routes_gtfs['route_long_name'].str.upper().str.strip()\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb021989-f7d1-4e16-a6e8-126b85e39dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GTFS data\n",
    "stops_gtfs = pd.read_csv('raw_data/gtfs_data/stops.txt')\n",
    "routes_gtfs = pd.read_csv('raw_data/gtfs_data/routes.txt')\n",
    "trips_gtfs = pd.read_csv('raw_data/gtfs_data/trips.txt')\n",
    "times_gtfs = pd.read_csv('raw_data/gtfs_data/stop_times.txt')\n",
    "\n",
    "# Clean GTFS stops\n",
    "def clean_data(stops_gtfs):\n",
    "    stops_gtfs['stop_name'] = stops_gtfs['stop_name'].str.upper().str.strip()\n",
    "    # Change column type to int32 for column: 'stop_id'\n",
    "    stops_gtfs = stops_gtfs.astype({'stop_id': 'int32'})\n",
    "    return stops_gtfs\n",
    "stops_gtfs_clean = clean_data(stops_gtfs.copy())\n",
    "\n",
    "# Clean GTFS routes\n",
    "def clean_data(routes_gtfs):\n",
    "    routes_gtfs['route_long_name'] = routes_gtfs['route_long_name'].str.upper().str.strip()\n",
    "    return routes_gtfs\n",
    "routes_gtfs_clean = clean_data(routes_gtfs.copy())\n",
    "\n",
    "# Clean GTFS trips\n",
    "def clean_data(trips_gtfs):\n",
    "    trips_gtfs['route_id'] = trips_gtfs['route_id'].str.strip()\n",
    "    trips_gtfs['service_id'] = trips_gtfs['service_id'].str.strip().str.upper()\n",
    "    trips_gtfs['trip_id'] = trips_gtfs['trip_id'].str.strip().str.upper()\n",
    "    trips_gtfs['trip_headsign'] = trips_gtfs['trip_headsign'].str.strip().str.upper()\n",
    "    return trips_gtfs\n",
    "trips_gtfs_clean = clean_data(trips_gtfs.copy())\n",
    "\n",
    "# Clean GTFS stop times\n",
    "def clean_data(times_gtfs):\n",
    "    times_gtfs['trip_id'] = times_gtfs['trip_id'].str.upper()\n",
    "    times_gtfs['arrival_time'] = times_gtfs['arrival_time'].str.replace(r'^24', '00', regex=True)\n",
    "    times_gtfs['departure_time'] = times_gtfs['departure_time'].str.replace(r'^24', '00', regex=True)\n",
    "    times_gtfs['trip_id'] = times_gtfs['trip_id'].str.strip()\n",
    "    times_gtfs['arrival_time'] = times_gtfs['arrival_time'].str.strip()\n",
    "    times_gtfs['departure_time'] = times_gtfs['departure_time'].str.strip()\n",
    "    return times_gtfs\n",
    "times_gtfs_clean = clean_data(times_gtfs.copy())\n",
    "\n",
    "mr.Markdown(f\"\"\"\n",
    "**GTFS Data Loaded:**\n",
    "- {len(stops_gtfs_clean)} stops\n",
    "- {len(routes_gtfs_clean)} routes\n",
    "- {len(trips_gtfs_clean)} trips\n",
    "- {len(times_gtfs_clean)} stop times\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb4748-fe0b-4252-b05f-aff1606c8df5",
   "metadata": {},
   "source": [
    " ## Transformation 2: Parsing Date/Time Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5231014-b75c-489f-9c78-9fec700c63fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "**Problem:** Time data stored as strings (HH:MM:SS)\n",
    "\n",
    "**Solution:** Parse to datetime and derive time-based features\n",
    "\n",
    "```python\n",
    "# Parse time columns\n",
    "times_gtfs_clean['arrival_datetime'] = pd.to_datetime(\n",
    "    times_gtfs_clean['arrival_time'], \n",
    "    format='%H:%M:%S',\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Derive hour and minute features\n",
    "times_gtfs_clean['arrival_hour'] = times_gtfs_clean['arrival_datetime'].dt.hour\n",
    "times_gtfs_clean['arrival_minute'] = times_gtfs_clean['arrival_datetime'].dt.minute\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0169e6d-2330-4f03-bd55-9f050e34f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse time columns\n",
    "times_gtfs_clean['arrival_datetime'] = pd.to_datetime(\n",
    "    times_gtfs_clean['arrival_time'], \n",
    "    format='%H:%M:%S',\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "times_gtfs_clean['departure_datetime'] = pd.to_datetime(\n",
    "    times_gtfs_clean['departure_time'], \n",
    "    format='%H:%M:%S',\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Derive hour of day\n",
    "times_gtfs_clean['arrival_hour'] = times_gtfs_clean['arrival_datetime'].dt.hour\n",
    "times_gtfs_clean['arrival_minute'] = times_gtfs_clean['arrival_datetime'].dt.minute\n",
    "\n",
    "mr.Markdown(\"✅ **Parsed time data and derived hour/minute features**\")\n",
    "times_gtfs_clean[['arrival_time', 'arrival_datetime', 'arrival_hour', 'arrival_minute']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3f640e-ae1a-4c5b-a400-ed0db725f0c8",
   "metadata": {},
   "source": [
    " ## Transformation 3: Merge/Join Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065557ff-37a7-4acb-8855-e2eac919775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "**Identifying missing stops:** GTFS data contains more stops than geographic data\n",
    "\n",
    "```python\n",
    "# Find stops in GTFS but not in geographic data\n",
    "missing_stops = stops_gtfs_clean[\n",
    "    ~stops_gtfs_clean['stop_id'].isin(clean_stops['stop_id'])\n",
    "]\n",
    "\n",
    "# Merge datasets\n",
    "merged_stops = pd.concat([clean_stops, missing_stops], ignore_index=True)\n",
    "\n",
    "# Impute missing street names from stop_name\n",
    "for index, stop in merged_stops.iterrows():\n",
    "    if pd.isna(stop['on_street']):\n",
    "        merged_stops.at[index, 'on_street'] = stop['stop_name'].split(' @')[0]\n",
    "    if pd.isna(stop['at_street']):\n",
    "        merged_stops.at[index, 'at_street'] = stop['stop_name'].split('@ ')[-1]\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58cce57-c85f-492d-a10e-137df0223e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure join keys have same type\n",
    "clean_stops['stop_id'] = clean_stops['stop_id'].astype(str)\n",
    "stops_gtfs_clean['stop_id'] = stops_gtfs_clean['stop_id'].astype(str)\n",
    "\n",
    "# Find missing stops\n",
    "missing_stops = stops_gtfs_clean[~stops_gtfs_clean['stop_id'].isin(clean_stops['stop_id'])]\n",
    "\n",
    "mr.Markdown(f\"**Found {len(missing_stops)} stops in GTFS not in geographic data**\")\n",
    "\n",
    "# Merge\n",
    "merged_stops = pd.concat([clean_stops, missing_stops], ignore_index=True, sort=False)\n",
    "\n",
    "# Impute missing values\n",
    "def clean_data(merged_stops):\n",
    "    for index, stop in merged_stops.iterrows():\n",
    "        if pd.isna(stop['on_street']):\n",
    "            merged_stops.at[index, 'on_street'] = str(merged_stops.at[index, 'stop_name']).split(' @')[0]\n",
    "        if pd.isna(stop['at_street']):\n",
    "            merged_stops.at[index, 'at_street'] = str(merged_stops.at[index, 'stop_name']).split('@ ')[-1]\n",
    "    return merged_stops\n",
    "\n",
    "merged_stops_clean = clean_data(merged_stops.copy())\n",
    "\n",
    "mr.Markdown(f\"✅ **Total stops after merge: {len(merged_stops_clean)} ({len(missing_stops)} added)**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d395a429-9752-45fc-80ae-1afce63c10ff",
   "metadata": {},
   "source": [
    " ## Transformation 4: Feature Derivation - Geographic Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe2f0e-fe60-45b8-8374-229408173375",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "**Derive regional classification** based on city center coordinates:\n",
    "\n",
    "```python\n",
    "city_center_lon = -104.618\n",
    "city_center_lat = 50.447\n",
    "\n",
    "# Assign quadrants (NE, NW, SE, SW)\n",
    "for stop in range(len(clean_stops)):\n",
    "    if float(clean_stops['lat'].iloc[stop]) > city_center_lat:\n",
    "        if float(clean_stops['lon'].iloc[stop]) > city_center_lon:\n",
    "            clean_stops.at[stop, 'region'] = \"NE\"\n",
    "        else:\n",
    "            clean_stops.at[stop, 'region'] = \"NW\"\n",
    "    else:\n",
    "        if float(clean_stops['lon'].iloc[stop]) > city_center_lon:\n",
    "            clean_stops.at[stop, 'region'] = \"SE\"\n",
    "        else:\n",
    "            clean_stops.at[stop, 'region'] = \"SW\"\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ee0f2-0bff-455b-8bae-c5ade5744ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive regions\n",
    "city_center_lon = -104.618\n",
    "city_center_lat = 50.447\n",
    "clean_stops['region'] = ''\n",
    "\n",
    "for stop in range(len(clean_stops)):\n",
    "    if float(clean_stops['lat'].iloc[stop]) > city_center_lat:\n",
    "        if float(clean_stops['lon'].iloc[stop]) > city_center_lon:\n",
    "            clean_stops.at[stop, 'region'] = \"NE\"\n",
    "        else:\n",
    "            clean_stops.at[stop, 'region'] = \"NW\"\n",
    "    else:\n",
    "        if float(clean_stops['lon'].iloc[stop]) > city_center_lon:\n",
    "            clean_stops.at[stop, 'region'] = \"SE\"\n",
    "        else:\n",
    "            clean_stops.at[stop, 'region'] = \"SW\"\n",
    "\n",
    "mr.Markdown(\"✅ **Derived regional classifications for all stops**\")\n",
    "\n",
    "# Show distribution\n",
    "region_counts = clean_stops['region'].value_counts()\n",
    "mr.Markdown(f\"\"\"\n",
    "**Stop distribution by region:**\n",
    "- NW: {region_counts.get('NW', 0)} stops\n",
    "- NE: {region_counts.get('NE', 0)} stops\n",
    "- SW: {region_counts.get('SW', 0)} stops\n",
    "- SE: {region_counts.get('SE', 0)} stops\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f450de26-5383-44ca-9150-98ac3c250bce",
   "metadata": {},
   "source": [
    " ## Transformation 5: Feature Derivation - Distance Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9213ba9a-2b19-417b-aa3b-a9fa108fabac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "**Calculate distance from city center** using coordinate geometry:\n",
    "\n",
    "```python\n",
    "# Approximate conversion: ~111 km per degree latitude, ~85 km per degree longitude at this latitude\n",
    "clean_stops['distance_from_center_km'] = np.sqrt(\n",
    "    ((clean_stops['lat'].astype(float) - city_center_lat) * 111)**2 + \n",
    "    ((clean_stops['lon'].astype(float) - city_center_lon) * 85)**2\n",
    ")\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f078001-7346-4b2c-a47a-4dc5e9fbe221",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_stops['distance_from_center_km'] = np.sqrt(\n",
    "    ((clean_stops['lat'].astype(float) - city_center_lat) * 111)**2 + \n",
    "    ((clean_stops['lon'].astype(float) - city_center_lon) * 85)**2\n",
    ")\n",
    "\n",
    "mr.Markdown(\"✅ **Calculated distance from city center for all stops**\")\n",
    "print(\"\\nDistance statistics (km):\")\n",
    "print(clean_stops['distance_from_center_km'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f9818c-a087-4cf2-8d5e-1f8746f9855c",
   "metadata": {},
   "source": [
    " ## Transformation 6: Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fafdf8-b687-41b0-afac-63fe439e8df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "**Aggregate stops by region** to understand service distribution:\n",
    "\n",
    "```python\n",
    "region_summary = clean_stops.groupby('region').agg({\n",
    "    'stop_id': 'count',\n",
    "    'distance_from_center_km': ['mean', 'max']\n",
    "}).reset_index()\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e9f44-39b0-46a1-a200-635a5b0bafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_summary = clean_stops.groupby('region').agg({\n",
    "    'stop_id': 'count',\n",
    "    'distance_from_center_km': ['mean', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "region_summary.columns = ['region', 'num_stops', 'avg_distance_km', 'max_distance_km']\n",
    "\n",
    "mr.Markdown(\"**Regional Summary Statistics:**\")\n",
    "region_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6588fa-0d46-4b50-9efa-f2d39530bfa1",
   "metadata": {},
   "source": [
    " ## Transformation 7: Reshape (Pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adea9b31-c76f-4c12-8add-5733c0bece81",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "**Pivot analysis:** How many stops does each route serve in each region?\n",
    "\n",
    "```python\n",
    "# Join stop times → trips → stops to get route-region relationships\n",
    "route_stops = (\n",
    "    times_gtfs_clean\n",
    "    .merge(trips_gtfs_clean[['trip_id', 'route_id']], on='trip_id')\n",
    "    .merge(clean_stops[['stop_id', 'region']], left_on='stop_id', right_on='stop_id')\n",
    "    .groupby(['route_id', 'region'])\n",
    "    .size()\n",
    "    .reset_index(name='stop_count')\n",
    ")\n",
    "\n",
    "# Pivot to wide format\n",
    "route_region_pivot = route_stops.pivot(\n",
    "    index='route_id', \n",
    "    columns='region', \n",
    "    values='stop_count'\n",
    ").fillna(0)\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af833683-d6a0-4cf5-86fd-fa190293f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure join keys have the same dtype to avoid merge mismatches\n",
    "# Cast stop_id/trip_id/route_id to string on both sides of joins\n",
    "times_gtfs_clean['trip_id'] = times_gtfs_clean['trip_id'].astype(str)\n",
    "trips_gtfs_clean['trip_id'] = trips_gtfs_clean['trip_id'].astype(str)\n",
    "times_gtfs_clean['stop_id'] = times_gtfs_clean['stop_id'].astype(str)\n",
    "clean_stops['stop_id'] = clean_stops['stop_id'].astype(str)\n",
    "trips_gtfs_clean['route_id'] = trips_gtfs_clean['route_id'].astype(str)\n",
    "\n",
    "route_stops = (\n",
    "    times_gtfs_clean\n",
    "    .merge(trips_gtfs_clean[['trip_id', 'route_id']], on='trip_id')\n",
    "    .merge(clean_stops[['stop_id', 'region']], left_on='stop_id', right_on='stop_id')\n",
    "    .groupby(['route_id', 'region'])\n",
    "    .size()\n",
    "    .reset_index(name='stop_count')\n",
    ")\n",
    "\n",
    "route_region_pivot = route_stops.pivot(\n",
    "    index='route_id', \n",
    "    columns='region', \n",
    "    values='stop_count'\n",
    ").fillna(0)\n",
    "\n",
    "mr.Markdown(\"**Routes by Region (Pivoted):**\")\n",
    "route_region_pivot.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285dc055-eef0-4539-a576-181432eb92e2",
   "metadata": {},
   "source": [
    " ## Profiling: Outliers & Cardinalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f491b513-7340-48e4-9370-f5480c7f3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "**Outlier Detection:** Identify stops unusually far from city center\n",
    "\n",
    "**Cardinality Analysis:** Count unique values in key dimensions\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de82e943-622f-420f-a721-852ba2ec9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== OUTLIERS ===\")\n",
    "print(\"Stops beyond 15km from city center:\")\n",
    "outliers = clean_stops[clean_stops['distance_from_center_km'] > 15]\n",
    "print(f\"Found {len(outliers)} outlier stops\")\n",
    "if len(outliers) > 0:\n",
    "    print(outliers[['stop_name', 'distance_from_center_km']].head())\n",
    "\n",
    "print(\"\\n=== CARDINALITIES ===\")\n",
    "print(f\"Unique stops: {clean_stops['stop_id'].nunique()}\")\n",
    "print(f\"Unique routes: {routes_gtfs_clean['route_id'].nunique()}\")\n",
    "print(f\"Unique regions: {clean_stops['region'].nunique()}\")\n",
    "print(f\"Unique trips: {trips_gtfs_clean['trip_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a0e29c-744c-47f9-b590-49b4ce344bcc",
   "metadata": {},
   "source": [
    " ## Before/After Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c0692-3a9d-4229-beb4-13178cf7f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "### Quantitative comparison of data quality improvements:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7083cdc-4d2a-4522-b29b-8cee977f0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BEFORE (Raw Data)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Stop rows: {len(df_stops)}\")\n",
    "print(f\"Route rows: {len(df_routes)}\")\n",
    "print(f\"Missing ATSTREET: {df_stops['attributes.ATSTREET'].isnull().sum()}\")\n",
    "print(f\"Coordinate type: {df_stops['attributes.LAT'].dtype} (string)\")\n",
    "print(f\"Stop ID type: {df_stops['attributes.STOP_ID'].dtype} (string)\")\n",
    "print(f\"Features: 8 columns\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"AFTER (Cleaned & Transformed)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Stop rows: {len(clean_stops)} (+{len(missing_stops)} from GTFS)\")\n",
    "print(f\"Route rows: {len(clean_routes)}\")\n",
    "print(f\"Missing ATSTREET: {clean_stops['at_street'].isnull().sum()}\")\n",
    "print(f\"Coordinate type: {clean_stops['lat'].dtype} (numeric-ready)\")\n",
    "print(f\"Stop ID type: {clean_stops['stop_id'].dtype} (int32)\")\n",
    "print(f\"Features: {len(clean_stops.columns)} columns\")\n",
    "print(f\"New derived features: region, distance_from_center_km\")\n",
    "print(f\"Parsed time features: arrival_hour, arrival_minute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5602fa5e-1f8e-4947-81f5-17229a1fa038",
   "metadata": {},
   "source": [
    " ## Visualization: Interactive Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e938e-019d-4009-a195-29c8273aa783",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "**Interactive map** showing all bus stops with hover information:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68393734-51ec-41e4-841b-9a8479113e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapted from the Plotly documentation https://plotly.com/python/tile-scatter-maps/#multiple-markers\n",
    "stop_fig = go.Figure(go.Scattermap(\n",
    "    lat=clean_stops['lat'],\n",
    "    lon=clean_stops['lon'],\n",
    "    mode='markers',\n",
    "    marker=go.scattermap.Marker(size=9, color='blue'),\n",
    "    text=clean_stops['stop_name'],\n",
    "    hovertemplate='<b>%{text}</b><extra></extra>'\n",
    "))\n",
    "\n",
    "stop_fig.update_layout(\n",
    "    title=\"Regina Transit Stops\",\n",
    "    autosize=True,\n",
    "    hovermode='closest',\n",
    "    map=dict(\n",
    "        bearing=0,\n",
    "        center=dict(lat=50.447992743219615, lon=-104.61228441057489),\n",
    "        pitch=0,\n",
    "        zoom=11\n",
    "    ),\n",
    "    height=600\n",
    ")\n",
    "\n",
    "stop_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4e4e74-be62-429e-9b1a-7491b9ca2ad3",
   "metadata": {},
   "source": [
    " ## Visualization: Route Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f0d42a-251f-4feb-bb36-c5b483449a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "**Adding route geometry** with coordinate transformation from UTM to lat/lon:\n",
    "\n",
    "```python\n",
    "# Transform UTM coordinates to lat/lon\n",
    "transformer = Transformer.from_crs(\"EPSG:26913\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "for coordinate in path:\n",
    "    lon, lat = transformer.transform(coordinate[0], coordinate[1])\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3856fe99-229c-4f0b-83f6-d4837c77c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer.from_crs(\"EPSG:26913\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "route_idx = 0\n",
    "route_name = clean_routes['route_name'].iloc[route_idx]\n",
    "route_geometry = clean_routes['geometry_paths'].iloc[route_idx]\n",
    "route_colour = clean_routes['route_color'].iloc[route_idx]\n",
    "\n",
    "# Transform coordinates\n",
    "all_lons = []\n",
    "all_lats = []\n",
    "\n",
    "for path in route_geometry:\n",
    "    for coordinate in path:\n",
    "        lon, lat = transformer.transform(coordinate[0], coordinate[1])\n",
    "        all_lons.append(lon)\n",
    "        all_lats.append(lat)\n",
    "    all_lons.append(None)\n",
    "    all_lats.append(None)\n",
    "\n",
    "# Add route to map\n",
    "stop_fig.add_trace(go.Scattermap(\n",
    "    lon=all_lons,\n",
    "    lat=all_lats,\n",
    "    mode='lines',\n",
    "    line=dict(width=3, color=route_colour),\n",
    "    name=route_name,\n",
    "    hovertemplate=f'<b>{route_name}</b><extra></extra>'\n",
    "))\n",
    "\n",
    "stop_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578867c0-12e6-4588-bd31-9486d9610b57",
   "metadata": {},
   "source": [
    " ## Summary of Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6872d00-6df5-4a53-b7d7-cffbc67d377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "### Completed Transformations (8 operations across 5 categories):\n",
    "\n",
    "**1. Type Fixes & Parsing**\n",
    "- ✅ Converted stop_id from string to int32\n",
    "- ✅ Parsed arrival/departure times to datetime\n",
    "- ✅ Derived hour and minute features\n",
    "\n",
    "**2. Text Cleanup**\n",
    "- ✅ Stripped whitespace from all text columns\n",
    "- ✅ Converted to uppercase for consistency\n",
    "- ✅ Fixed malformed addresses\n",
    "\n",
    "**3. Missing Data Handling**\n",
    "- ✅ Imputed missing ATSTREET values\n",
    "- ✅ Generated street names from stop names for GTFS stops\n",
    "\n",
    "**4. Join/Merge**\n",
    "- ✅ Merged geographic stops with GTFS schedule data\n",
    "- ✅ Joined stop times → trips → routes → stops\n",
    "\n",
    "**5. Feature Derivation**\n",
    "- ✅ Created regional classifications (NE, NW, SE, SW)\n",
    "- ✅ Calculated distance from city center\n",
    "\n",
    "**6. Aggregation**\n",
    "- ✅ Summarized stops by region with statistics\n",
    "\n",
    "**7. Reshape**\n",
    "- ✅ Pivoted route-region stop counts to wide format\n",
    "\n",
    "**8. Coordinate Transformation**\n",
    "- ✅ Converted UTM to lat/lon for visualization\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b22eb9-6226-41c6-a952-701a19fa5292",
   "metadata": {},
   "source": [
    " ## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18882d-3130-4d26-9e3d-6c860aa635ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"\n",
    "### How to reproduce this analysis:\n",
    "\n",
    "**1. Install dependencies:**\n",
    "```bash\n",
    "pip install pandas plotly pyproj numpy jupyter mercury\n",
    "```\n",
    "\n",
    "**2. Directory structure:**\n",
    "```\n",
    "project/\n",
    "├── presentation.ipynb\n",
    "├── raw_data/\n",
    "│   ├── yqrStops20251120.json\n",
    "│   ├── yqrRoutes20251120.json\n",
    "│   └── gtfs_data/\n",
    "│       ├── stops.txt\n",
    "│       ├── routes.txt\n",
    "│       ├── trips.txt\n",
    "│       └── stop_times.txt\n",
    "└── README.md\n",
    "```\n",
    "\n",
    "**3. Run notebook:**\n",
    "- Execute all cells sequentially\n",
    "- Or run with Mercury: `mercury run presentation.ipynb`\n",
    "\n",
    "**Tool versions:** Python 3.14, pandas 2.2.3, plotly 5.24.1, pyproj 3.7.0\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
