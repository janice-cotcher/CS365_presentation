{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c667032",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f644681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from IPython.core.magic import register_cell_magic\n",
    "from IPython import get_ipython\n",
    "# Conditional skipping of https://kioku-space.com/en/jupyter-skip-execution/\n",
    "@register_cell_magic\n",
    "def skip_if(line, cell):\n",
    "    if eval(line):\n",
    "        return\n",
    "    get_ipython().run_cell(cell)\n",
    "\n",
    "get_ipython().register_magic_function(skip_if, 'cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572b6cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if importlib.util.find_spec('Jinja2') is not None\n",
    "%pip install Jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae6b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if importlib.util.find_spec('nbformat') is not None\n",
    "%pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a13a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mercury as mr\n",
    "import nbformat\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import pandas as pd\n",
    "import json\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1663c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('raw_data/yqrStops.json', 'r') as f:\n",
    "        stop_data = json.load(f)\n",
    "except json.decoder.JSONDecodeError as e:\n",
    "    print(\"Invalid JSON\", e)\n",
    "\n",
    "stop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb0bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stops = pd.json_normalize(stop_data)\n",
    "df_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f92b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stops = pd.json_normalize(stop_data['features'])\n",
    "df_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b9ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bus Stop Data Types\")\n",
    "print(df_stops.dtypes[df_stops.columns[:8]])\n",
    "print(\"---------------------------------\")\n",
    "print(f\"\\nSample LAT values: {df_stops['attributes.LAT'].head(2).tolist()}\")\n",
    "print(\"Bus Stop Missing Values\")\n",
    "missing = df_stops.isnull().sum()\n",
    "print(missing[missing > 0])\n",
    "print(\"---------------------------------\")\n",
    "print(\"Bus Stop Duplicates\")\n",
    "duplicates = df_stops.duplicated(subset=['attributes.STOP_ID']).sum()\n",
    "print(f\"Duplicate stop IDs: {duplicates}\")\n",
    "print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbba5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"======Sample Raw Bus Stop Data=======\")\n",
    "df_stops[['attributes.STOP_ID','attributes.ONSTREET', 'attributes.ATSTREET', 'attributes.LAT', 'attributes.LON']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deeb88f",
   "metadata": {},
   "source": [
    "# Cleaning Bus Stop data using Data Wrangler extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell generated by Data Wrangler.\n",
    "\"\"\"\n",
    "def clean_data(df_stops):\n",
    "    # Remove leading and trailing whitespace in column: 'attributes.ONSTREET'\n",
    "    df_stops['attributes.ONSTREET'] = df_stops['attributes.ONSTREET'].str.strip()\n",
    "    # Convert text to uppercase in column: 'attributes.ONSTREET'\n",
    "    df_stops['attributes.ONSTREET'] = df_stops['attributes.ONSTREET'].str.upper()\n",
    "    # Remove leading and trailing whitespace in column: 'attributes.ATSTREET'\n",
    "    df_stops['attributes.ATSTREET'] = df_stops['attributes.ATSTREET'].str.strip()\n",
    "    # Convert text to uppercase in column: 'attributes.ATSTREET'\n",
    "    df_stops['attributes.ATSTREET'] = df_stops['attributes.ATSTREET'].str.upper()\n",
    "    # Remove leading and trailing whitespace in column: 'attributes.LON'\n",
    "    df_stops['attributes.LON'] = df_stops['attributes.LON'].str.strip()\n",
    "    # Remove leading and trailing whitespace in column: 'attributes.LAT'\n",
    "    df_stops['attributes.LAT'] = df_stops['attributes.LAT'].str.strip()\n",
    "    # Remove leading and trailing whitespace in column: 'stop_id'\n",
    "    df_stops['attributes.STOP_ID'] = df_stops['attributes.STOP_ID'].str.strip()\n",
    "    # Remove leading and trailing whitespace in column: 'attributes.STOP_NAME'\n",
    "    df_stops['attributes.STOP_NAME'] = df_stops['attributes.STOP_NAME'].str.strip()\n",
    "    # Convert text to uppercase in column: 'attributes.STOP_NAME'\n",
    "    df_stops['attributes.STOP_NAME'] = df_stops['attributes.STOP_NAME'].str.upper()\n",
    "    # Remove leading and trailing whitespace in column: 'attributes.GLOBALID'\n",
    "    df_stops['attributes.GLOBALID'] = df_stops['attributes.GLOBALID'].str.strip()\n",
    "    # Replace missing values with \"DOROTHY ST (SB)\" in column: 'attributes.ATSTREET'\n",
    "    df_stops = df_stops.fillna({'attributes.ATSTREET':\"DOROTHY ST (SB)\"})\n",
    "    # Replace all instances of \"1060 DOROTHY ST (SB)\" with \"DOROTHY ST\" in column: 'attributes.ONSTREET'\n",
    "    df_stops['attributes.ONSTREET'] = df_stops['attributes.ONSTREET'].str.replace(\"1060 DOROTHY ST (SB)\", \"DOROTHY ST\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'stop_id'\n",
    "    df_stops = df_stops.astype({'attributes.STOP_ID': 'int32'})\n",
    "    # Rename column 'attributes.ONSTREET' to 'on_street'\n",
    "    df_stops = df_stops.rename(columns={'attributes.ONSTREET': 'on_street'})\n",
    "    # Rename column 'attributes.ATSTREET' to 'at_street'\n",
    "    df_stops = df_stops.rename(columns={'attributes.ATSTREET': 'at_street'})\n",
    "    # Rename column 'attributes.LON' to 'lon'\n",
    "    df_stops = df_stops.rename(columns={'attributes.LON': 'lon'})\n",
    "    # Rename column 'attributes.LAT' to 'lat'\n",
    "    df_stops = df_stops.rename(columns={'attributes.LAT': 'lat'})\n",
    "    # Rename column 'stop_id' to 'stop_id'\n",
    "    df_stops = df_stops.rename(columns={'attributes.STOP_ID': 'stop_id'})\n",
    "    # Rename column 'attributes.STOP_NAME' to 'stop_name'\n",
    "    df_stops = df_stops.rename(columns={'attributes.STOP_NAME': 'stop_name'})\n",
    "    # Rename column 'attributes.GLOBALID' to 'global_id'\n",
    "    df_stops = df_stops.rename(columns={'attributes.GLOBALID': 'global_id'})\n",
    "    # Rename column 'attributes.OBJECTID' to 'object_id'\n",
    "    df_stops = df_stops.rename(columns={'attributes.OBJECTID': 'object_id'})\n",
    "    return df_stops\n",
    "\n",
    "clean_stops = clean_data(df_stops.copy())\n",
    "clean_stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b1286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('raw_data/yqrRoutes.json', 'r') as f:\n",
    "        routes_data = json.load(f)\n",
    "    print(\"âœ“ Loaded routes data\")\n",
    "except json.decoder.JSONDecodeError as e:\n",
    "    print(\"Invalid JSON\", e)\n",
    "\n",
    "df_routes = pd.json_normalize(routes_data['features'])\n",
    "df_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4a311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bus Route Data Types\")\n",
    "print(df_routes.dtypes[df_routes.columns[:8]])\n",
    "print(\"---------------------------------\")\n",
    "print(\"Bus Route Missing Values\")\n",
    "missing = df_routes.isnull().sum()\n",
    "print(missing[missing > 0])\n",
    "print(\"---------------------------------\")\n",
    "print(\"Bus Route Duplicates\")\n",
    "duplicates = df_routes.duplicated(subset=['attributes.ROUTE_ID']).sum()\n",
    "print(f\"Duplicate stop IDs: {duplicates}\")\n",
    "print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da49f1fb",
   "metadata": {},
   "source": [
    "# Cleaning Bus Route Data using Data Wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffec0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell generated by Data Wrangler.\n",
    "\"\"\"\n",
    "def clean_data(df_routes):\n",
    "    # Remove leading and trailing whitespace in columns: 'attributes.ROUTE_NAME', 'attributes.ROUTE_NUM' and 4 other columns\n",
    "    df_routes['attributes.ROUTE_NAME'] = df_routes['attributes.ROUTE_NAME'].str.strip()\n",
    "    df_routes['attributes.ROUTE_NUM'] = df_routes['attributes.ROUTE_NUM'].str.strip()\n",
    "    df_routes['attributes.ROUTE_ID'] = df_routes['attributes.ROUTE_ID'].str.strip()\n",
    "    df_routes['attributes.SHAPE_ID'] = df_routes['attributes.SHAPE_ID'].str.strip()\n",
    "    # add a hashtag in front of the route colour hex values \n",
    "    df_routes['attributes.ROUTE_COLOR'] = '#' + (df_routes['attributes.ROUTE_COLOR'].str.strip()).astype(str)\n",
    "    # Convert text to uppercase in column: 'attributes.ROUTE_NAME'\n",
    "    df_routes['attributes.ROUTE_NAME'] = df_routes['attributes.ROUTE_NAME'].str.upper()\n",
    "    # Replace missing values with \"FFFFFF\" in column: 'attributes.ROUTE_TEXT_COLOR'\n",
    "    df_routes = df_routes.fillna({'attributes.ROUTE_TEXT_COLOR': \"FFFFFF\"})\n",
    "    # add a hashtag in front of the route text colour hex values\n",
    "    df_routes['attributes.ROUTE_TEXT_COLOR'] = \"#\"+ (df_routes['attributes.ROUTE_TEXT_COLOR'].str.strip()).astype(str)\n",
    "     # Rename column 'attributes.SHAPE.LEN' to 'shape_length'\n",
    "    df_routes = df_routes.rename(columns={'attributes.SHAPE.LEN': 'shape_length'})\n",
    "    # Rename column 'attributes.ROUTE_NAME' to 'route_name'\n",
    "    df_routes = df_routes.rename(columns={'attributes.ROUTE_NAME': 'route_name'})\n",
    "    # Rename column 'attributes.ROUTE_NUM' to 'route_num'\n",
    "    df_routes = df_routes.rename(columns={'attributes.ROUTE_NUM': 'route_num'})\n",
    "    # Rename column 'attributes.ROUTE_ID' to 'route_id'\n",
    "    df_routes = df_routes.rename(columns={'attributes.ROUTE_ID': 'route_id'})\n",
    "    # Rename column 'attributes.SHAPE_ID' to 'shape_id'\n",
    "    df_routes = df_routes.rename(columns={'attributes.SHAPE_ID': 'shape_id'})\n",
    "    # Rename column 'attributes.ROUTE_COLOR' to 'route_color'\n",
    "    df_routes = df_routes.rename(columns={'attributes.ROUTE_COLOR': 'route_color'})\n",
    "    # Rename column 'attributes.ROUTE_TEXT_COLOR' to 'route_text_color'\n",
    "    df_routes = df_routes.rename(columns={'attributes.ROUTE_TEXT_COLOR': 'route_text_color'})\n",
    "    # Rename column 'geometry.paths' to 'geometry_paths'\n",
    "    df_routes = df_routes.rename(columns={'geometry.paths': 'geometry_paths'})\n",
    "    # Rename column 'attributes.OBJECTID' to 'object_id'\n",
    "    df_routes = df_routes.rename(columns={'attributes.OBJECTID': 'object_id'})\n",
    "    return df_routes\n",
    "\n",
    "clean_routes = clean_data(df_routes.copy())\n",
    "clean_routes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ee88db",
   "metadata": {},
   "source": [
    "# Loading GTFS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabccaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gtfs data\n",
    "stops_gtfs = pd.read_csv('raw_data/gtfs_data/stops.txt')\n",
    "routes_gtfs = pd.read_csv('raw_data/gtfs_data/routes.txt')\n",
    "trips_gtfs = pd.read_csv('raw_data/gtfs_data/trips.txt')\n",
    "times_gtfs = pd.read_csv('raw_data/gtfs_data/stop_times.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_gtfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aa419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell generated by Data Wrangler.\n",
    "\"\"\"\n",
    "def clean_data(stops_gtfs):\n",
    "    # Convert text to uppercase in column: 'stop_name'\n",
    "    stops_gtfs['stop_name'] = stops_gtfs['stop_name'].str.upper()\n",
    "    # Remove leading and trailing whitespace in column: 'stop_name'\n",
    "    stops_gtfs['stop_name'] = stops_gtfs['stop_name'].str.strip()\n",
    "    return stops_gtfs\n",
    "\n",
    "stops_gtfs_clean = clean_data(stops_gtfs.copy())\n",
    "stops_gtfs_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087303f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_gtfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cfb380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell generated by Data Wrangler.\n",
    "\"\"\"\n",
    "def clean_data(routes_gtfs):\n",
    "    # Convert text to uppercase in column: 'route_long_name'\n",
    "    routes_gtfs['route_long_name'] = routes_gtfs['route_long_name'].str.upper()\n",
    "    # Remove leading and trailing whitespace in column: 'route_long_name'\n",
    "    routes_gtfs['route_long_name'] = routes_gtfs['route_long_name'].str.strip()\n",
    "    return routes_gtfs\n",
    "\n",
    "routes_gtfs_clean = clean_data(routes_gtfs.copy())\n",
    "routes_gtfs_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d611acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_gtfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb4e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell generated by Data Wrangler.\n",
    "\"\"\"\n",
    "def clean_data(trips_gtfs):\n",
    "    # Remove leading and trailing whitespace in columns: 'route_id', 'service_id' and 2 other columns\n",
    "    trips_gtfs['route_id'] = trips_gtfs['route_id'].str.strip()\n",
    "    trips_gtfs['service_id'] = trips_gtfs['service_id'].str.strip()\n",
    "    trips_gtfs['trip_id'] = trips_gtfs['trip_id'].str.strip()\n",
    "    trips_gtfs['trip_headsign'] = trips_gtfs['trip_headsign'].str.strip()\n",
    "    # Convert text to uppercase in columns: 'service_id', 'trip_id', 'trip_headsign'\n",
    "    trips_gtfs['service_id'] = trips_gtfs['service_id'].str.upper()\n",
    "    trips_gtfs['trip_id'] = trips_gtfs['trip_id'].str.upper()\n",
    "    trips_gtfs['trip_headsign'] = trips_gtfs['trip_headsign'].str.upper()\n",
    "    return trips_gtfs\n",
    "\n",
    "trips_gtfs_clean = clean_data(trips_gtfs.copy())\n",
    "trips_gtfs_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9553c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_gtfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e7d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell generated by Data Wrangler.\n",
    "\"\"\"\n",
    "def clean_data(times_gtfs):\n",
    "    # Convert text to uppercase in column: 'trip_id'\n",
    "    times_gtfs['trip_id'] = times_gtfs['trip_id'].str.upper()\n",
    "    # Replace '24' in hour position with '00'\n",
    "    times_gtfs['arrival_time'] = times_gtfs['arrival_time'].str.replace(r'^24', '00', regex=True)\n",
    "    times_gtfs['departure_time'] = times_gtfs['departure_time'].str.replace(r'^24', '00', regex=True)\n",
    "    # Remove leading and trailing whitespace in columns: 'trip_id', 'arrival_time', 'departure_time'\n",
    "    times_gtfs['trip_id'] = times_gtfs['trip_id'].str.strip()\n",
    "    times_gtfs['arrival_time'] = times_gtfs['arrival_time'].str.strip()\n",
    "    times_gtfs['departure_time'] = times_gtfs['departure_time'].str.strip()\n",
    "    return times_gtfs\n",
    "\n",
    "times_gtfs_clean = clean_data(times_gtfs.copy())\n",
    "times_gtfs_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b08b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse time columns\n",
    "times_gtfs_clean['arrival_datetime'] = pd.to_datetime(\n",
    "    times_gtfs_clean['arrival_time'], \n",
    "    format='%H:%M:%S',\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "times_gtfs_clean['departure_datetime'] = pd.to_datetime(\n",
    "    times_gtfs_clean['departure_time'], \n",
    "    format='%H:%M:%S',\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Derive hour of day\n",
    "times_gtfs_clean['arrival_hour'] = times_gtfs_clean['arrival_datetime'].dt.hour\n",
    "times_gtfs_clean['arrival_minute'] = times_gtfs_clean['arrival_datetime'].dt.minute\n",
    "\n",
    "print(\"Sample parsed times:\")\n",
    "print(times_gtfs_clean[['arrival_time', 'arrival_datetime', 'arrival_hour', 'arrival_minute']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144e96a3",
   "metadata": {},
   "source": [
    "# Imputation\n",
    "## Find missing bus stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be44c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(clean_stops))\n",
    "print(len(stops_gtfs_clean))\n",
    "if len(stops_gtfs_clean) > len(clean_stops):\n",
    "    print(f\"There are {len(stops_gtfs_clean)-len(clean_stops)} missing stops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c755d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the join keys have the same data type\n",
    "clean_stops['stop_id'] = clean_stops['stop_id'].astype(str)\n",
    "stops_gtfs_clean['stop_id'] = stops_gtfs_clean['stop_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32f7f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the missing stops\n",
    "missing_stops = stops_gtfs_clean[~stops_gtfs_clean['stop_id'].isin(clean_stops['stop_id'])]\n",
    "len(missing_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9505e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_stops = pd.concat([clean_stops, missing_stops], ignore_index=True, sort=False)\n",
    "merged_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b5afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(missing_stops), \"new stops added\")\n",
    "merged_stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb10497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell generated by Data Wrangler.\n",
    "\"\"\"\n",
    "def clean_data(merged_stops):\n",
    "    for index, stop in merged_stops.iterrows():\n",
    "        if pd.isna(stop['on_street']):\n",
    "            merged_stops.at[index, 'on_street'] = (\n",
    "                str(merged_stops.at[index, 'stop_name']).split(' @')[0]\n",
    "            )\n",
    "        if pd.isna(stop['at_street']):\n",
    "            merged_stops.at[index, 'at_street'] = (\n",
    "                str(merged_stops.at[index, 'stop_name']).split('@ ')[-1]\n",
    "            )\n",
    "    return merged_stops\n",
    "\n",
    "merged_stops_clean = clean_data(merged_stops.copy())\n",
    "merged_stops_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65101750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapted from the Plotly documentation https://plotly.com/python/tile-scatter-maps/#multiple-markers\n",
    "stop_fig = go.Figure(go.Scattermap(\n",
    "    lat=clean_stops['lat'],\n",
    "    lon=clean_stops['lon'],\n",
    "    mode='markers',\n",
    "    marker=go.scattermap.Marker(size=9),\n",
    "    text=clean_stops['stop_name'],\n",
    "))\n",
    "\n",
    "stop_fig.update_layout(\n",
    "    autosize=True,\n",
    "    hovermode='closest',\n",
    "    map=dict(\n",
    "        bearing=0,\n",
    "        center=dict(lat=50.447992743219615, lon=-104.61228441057489),\n",
    "        pitch=0,\n",
    "        zoom=10\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a6dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if importlib.util.find_spec('pyproj') is not None\n",
    "%pip install pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373acf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f32ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformer to convert from UTM to lat/lon\n",
    "transformer = Transformer.from_crs(\"EPSG:26913\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "route_idx = 0\n",
    "\n",
    "route_name = clean_routes['route_name'].iloc[route_idx]\n",
    "route_geometry = clean_routes['geometry_paths'].iloc[route_idx]\n",
    "route_colour = clean_routes['route_color'].iloc[route_idx]\n",
    "route_text_colour = clean_routes['route_text_color'].iloc[route_idx]\n",
    "\n",
    "# Combine all paths into single lists\n",
    "all_lons = []\n",
    "all_lats = []\n",
    "\n",
    "for path in route_geometry:\n",
    "    for coordinate in path:\n",
    "        lon, lat = transformer.transform(coordinate[0], coordinate[1])\n",
    "        all_lons.append(lon)\n",
    "        all_lats.append(lat)\n",
    "    \n",
    "    # Add None to separate path segments (prevents connecting them)\n",
    "    all_lons.append(None)\n",
    "    all_lats.append(None)\n",
    "\n",
    "# Add as ONE trace\n",
    "stop_fig.add_trace(go.Scattermap(\n",
    "    lon=all_lons,\n",
    "    lat=all_lats,\n",
    "    mode='lines',\n",
    "    line=dict(width=3, color=route_colour),\n",
    "    name=route_name,\n",
    "    hovertemplate=f'<b>{route_name}</b><extra></extra>'\n",
    "))\n",
    "\n",
    "stop_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adaf00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation: Bus Stops by Region\n",
    "\n",
    "city_center_lon = -104.618\n",
    "city_center_lat = 50.447\n",
    "clean_stops['region'] = ''\n",
    "\n",
    "for stop in range(len(clean_stops)):\n",
    "    if float(clean_stops['lat'].iloc[stop]) > city_center_lat:\n",
    "        if float(clean_stops['lon'].iloc[stop]) > city_center_lon:\n",
    "            clean_stops.at[stop, 'region'] = \"NE\"\n",
    "        else:\n",
    "            clean_stops.at[stop, 'region'] = \"NW\"\n",
    "    else:\n",
    "        if float(clean_stops['lon'].iloc[stop]) > city_center_lon:\n",
    "            clean_stops.at[stop, 'region'] = \"SE\"\n",
    "        else:\n",
    "            clean_stops.at[stop, 'region'] = \"SW\"\n",
    "\n",
    "clean_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e79ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwStops = clean_stops[clean_stops['region'] == 'NW']\n",
    "neStops = clean_stops[clean_stops['region'] == 'NE']\n",
    "swStops = clean_stops[clean_stops['region'] == 'SW']\n",
    "seStops = clean_stops[clean_stops['region'] == 'SE']\n",
    "\n",
    "nwStops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f6af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "neStops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a166f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "swStops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92812058",
   "metadata": {},
   "outputs": [],
   "source": [
    "seStops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef440176",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(clean_stops) == len(nwStops)+len(neStops) + len(swStops) + len(seStops):\n",
    "    print(\"True\")\n",
    "else:\n",
    "    print(\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29241a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_stops['distance_from_center_km'] = np.sqrt(\n",
    "    ((clean_stops['lat'].astype(float) - city_center_lat) * 111)**2 +  # 111 km per degree lat\n",
    "    ((clean_stops['lon'].astype(float) - city_center_lon) * 85)**2     # ~85 km per degree lon at this latitude\n",
    ")\n",
    "\n",
    "print(\"Distance statistics (km):\")\n",
    "print(clean_stops['distance_from_center_km'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb76c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation - Region Summary\n",
    "\n",
    "region_summary = clean_stops.groupby('region').agg({\n",
    "    'stop_id': 'count',\n",
    "    'distance_from_center_km': ['mean', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "region_summary.columns = ['region', 'num_stops', 'avg_distance_km', 'max_distance_km']\n",
    "print(\"Stops by region:\")\n",
    "print(region_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a6557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers\n",
    "print(\"=== OUTLIERS ===\")\n",
    "print(f\"Distance from center - outliers beyond 15km:\")\n",
    "outliers = clean_stops[clean_stops['distance_from_center_km'] > 15]\n",
    "print(f\"Found {len(outliers)} stops beyond 15km\")\n",
    "print(outliers[['stop_name', 'distance_from_center_km']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe44f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardinalities\n",
    "print(\"\\n=== FIX - CARDINALITIES ===\")\n",
    "print(f\"Unique stops: {clean_stops['stop_id'].nunique()}\")\n",
    "print(f\"Unique routes: {routes_gtfs_clean['route_id'].nunique()}\")\n",
    "print(f\"Unique regions: {clean_stops['region'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582c91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape: Routes by Region\n",
    "times_gtfs_clean['trip_id'] = times_gtfs_clean['trip_id'].astype(str)\n",
    "trips_gtfs_clean['trip_id'] = trips_gtfs_clean['trip_id'].astype(str)\n",
    "times_gtfs_clean['stop_id'] = times_gtfs_clean['stop_id'].astype(str)\n",
    "clean_stops['stop_id'] = clean_stops['stop_id'].astype(str)\n",
    "trips_gtfs_clean['route_id'] = trips_gtfs_clean['route_id'].astype(str)\n",
    "\n",
    "route_stops = (\n",
    "    times_gtfs_clean\n",
    "    .merge(trips_gtfs_clean[['trip_id', 'route_id']], on='trip_id')\n",
    "    .merge(clean_stops[['stop_id', 'region']], left_on='stop_id', right_on='stop_id')\n",
    "    .groupby(['route_id', 'region'])\n",
    "    .size()\n",
    "    .reset_index(name='stop_count')\n",
    ")\n",
    "\n",
    "# Pivot wider\n",
    "route_region_pivot = route_stops.pivot(\n",
    "    index='route_id', \n",
    "    columns='region', \n",
    "    values='stop_count'\n",
    ").fillna(0)\n",
    "\n",
    "print(\"FIX - Routes by region (pivoted):\")\n",
    "print(route_region_pivot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before and After Evidence\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"BEFORE (Raw Data)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Stop rows: {len(df_stops)}\")\n",
    "print(f\"Route rows: {len(df_routes)}\")\n",
    "print(f\"Missing ATSTREET: {df_stops['attributes.ATSTREET'].isnull().sum()}\")\n",
    "print(f\"String coordinates: {df_stops['attributes.LAT'].dtype}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"AFTER (Cleaned & Transformed)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Stop rows: {len(clean_stops)} (added {len(missing_stops)} from GTFS)\")\n",
    "print(f\"Route rows: {len(clean_routes)}\")\n",
    "print(f\"Missing ATSTREET: {clean_stops['at_street'].isnull().sum()}\")\n",
    "print(f\"Numeric coordinates: {clean_stops['lat'].dtype}\")\n",
    "print(f\"New features: region, distance_from_center_km\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
